{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0d0e14",
   "metadata": {},
   "source": [
    "# 1. Split the data into folds for training/validation/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b70cd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from pyment.data import NiftiDataset\n",
    "from pyment.labels import BinaryLabel\n",
    "\n",
    "\n",
    "data_folder = os.path.join(os.path.expanduser('~'), 'data', 'IXI', 'resized')\n",
    "project_folder = os.path.join(os.path.expanduser('~'), 'projects', 'brain-sex')\n",
    "\n",
    "if not os.path.isdir(project_folder):\n",
    "    os.mkdir(project_folder)\n",
    "\n",
    "if not os.path.isdir(os.path.join(project_folder, 'data')):\n",
    "    os.mkdir(os.path.join(project_folder, 'data'))\n",
    "    label = BinaryLabel(name='sex', mapping={'M': 0, 'F': 1})\n",
    "\n",
    "    dataset = NiftiDataset.from_folder(data_folder, encoders={'sex': label})\n",
    "    test_folds = dataset.stratified_folds(5, variables=['sex', 'scanner', 'age'])\n",
    "    test = test_folds[2]\n",
    "    train = reduce(lambda x, y: x + y, [test_folds[i] for i in range(len(test_folds)) \\\n",
    "                                        if i != 2])\n",
    "\n",
    "    folds = train.stratified_folds(5, variables=['sex', 'scanner', 'age'])\n",
    "    print(folds)\n",
    "    \n",
    "    test.save(os.path.join(os.path.join(project_folder, 'data', 'test.json')))\n",
    "    \n",
    "    for i in range(len(folds)):\n",
    "        folds[i].save(os.path.join(project_folder, 'data', f'fold_{i}.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2507f1",
   "metadata": {},
   "source": [
    "# 2. Configure a binary SFCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89b52a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 15:21:22,420 - WARNING - tensorflow: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2022-01-29 15:21:23,541 - WARNING - absl: Function `_wrapped_model` contains input name(s) Regression3DSFCN/inputs with unsupported characters which will be renamed to regression3dsfcn_inputs in the SavedModel.\n",
      "2022-01-29 15:21:25,476 - INFO - tensorflow: Assets written to: /home/esten/projects/brain-sex/model/assets\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from pyment.models import Model, RegressionSFCN\n",
    "\n",
    "backbone = RegressionSFCN(input_shape=[43, 54, 41], weights='brain-age', include_top=False, \n",
    "                          dropout=0.5, weight_decay=1e-3)\n",
    "\n",
    "head = Dense(1, activation='sigmoid')(backbone.output)\n",
    "\n",
    "model = Model(backbone.input, head)\n",
    "\n",
    "model = model.save(os.path.join(project_folder, 'model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d7ec38",
   "metadata": {},
   "source": [
    "# 3. Configure a preprocessor, an augmenter and a learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "866dcf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NiftiPreprocessor({\n",
      "    \"sigma\": 255.0\n",
      "})\n",
      "NiftiAugmenter({\n",
      "    \"flip_probabilities\": [\n",
      "        0.5,\n",
      "        0,\n",
      "        0\n",
      "    ]\n",
      "})\n",
      "LearningRateSchedule({\n",
      "    \"schedule\": {\n",
      "        \"0\": 0.0001,\n",
      "        \"20\": 1e-05\n",
      "    }\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from pyment.data.augmenters import NiftiAugmenter\n",
    "from pyment.data.preprocessors import NiftiPreprocessor\n",
    "from pyment.utils.learning_rate import LearningRateSchedule\n",
    "\n",
    "# Create a preprocessor which normalizes the images to the range [0, 1]\n",
    "preprocessor = NiftiPreprocessor(sigma=255.)\n",
    "preprocessor.save(os.path.join(project_folder, 'preprocessor.json'))\n",
    "print(preprocessor)\n",
    "\n",
    "augmenter = NiftiAugmenter(flip_probabilities=[0.5, 0, 0])\n",
    "augmenter.save(os.path.join(project_folder, 'augmenter.json'))\n",
    "print(augmenter)\n",
    "\n",
    "learning_rate_schedule = LearningRateSchedule({0: 1e-4, 20: 1e-5})\n",
    "learning_rate_schedule.save(os.path.join(project_folder, 'learning_rate_schedule.json'))\n",
    "print(learning_rate_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771ecf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-29 15:21:38,463 - INFO - tensorflow: Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "2022-01-29 15:21:39,849 - WARNING - tensorflow: No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/esten/projects/brain-sex/data/fold_0.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19391/1400625241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m           \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m           destination=run_folder)\n\u001b[0m",
      "\u001b[0;32m~/repos/pyment-public/scripts/fit_model.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, training, validation, preprocessor, augmenter, batch_size, num_threads, loss, metrics, learning_rate_schedule, epochs, domain, destination)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         training = [load_dataset_from_jsonfile(filename) \\\n\u001b[0;32m---> 64\u001b[0;31m                     for filename in training]\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/pyment-public/scripts/fit_model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         training = [load_dataset_from_jsonfile(filename) \\\n\u001b[0;32m---> 64\u001b[0;31m                     for filename in training]\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/pyment-public/pyment/data/datasets/__init__.py\u001b[0m in \u001b[0;36mload_dataset_from_jsonfile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset_from_jsonfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/esten/projects/brain-sex/data/fold_0.json'"
     ]
    }
   ],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "from fit_model import fit_model\n",
    "\n",
    "run_folder = os.path.join(project_folder, 'run')\n",
    "\n",
    "if os.path.isdir(run_folder):\n",
    "    rmtree(run_folder)\n",
    "    \n",
    "fit_model(model=os.path.join(project_folder, 'model'),\n",
    "          training=[os.path.join(project_folder, 'data', f'fold_{i}.json') \\\n",
    "                    for i in range(4)],\n",
    "          validation=[os.path.join(project_folder, 'data', f'fold_4.json')],\n",
    "          preprocessor=os.path.join(project_folder, 'preprocessor.json'),\n",
    "          augmenter=os.path.join(project_folder, 'augmenter.json'),\n",
    "          batch_size=4,\n",
    "          num_threads=8,\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['accuracy'],\n",
    "          learning_rate_schedule=os.path.join(project_folder, 'learning_rate_schedule.json'),\n",
    "          epochs=40,\n",
    "          domain=None,\n",
    "          destination=run_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a11a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
